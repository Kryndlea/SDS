---
title: "Population as a raster grid"
format:
  html: default
  ipynb: default
jupyter: sds
---

::: {.callout-caution}
This course material is currently under construction and is likely incomplete. The final
version will be released in October 2023.
:::

Until now, all the data you were working with were tables. However, not everything is a
table. Raster data are not that common in social geography, but spatial data science is
full of it, from satellite imagery to population grids. In this session, you will learn
how to work with spatial raster data in Python and how to link raster to vector using
the ecosystem around the `xarray` package.

## Arrays and their many dimensions

Raster data are represented as arrays. Those can take many forms and shapes. You already
know `pandas` data structures, so let's start with those.

A `pandas.Series` is a
1-dimensional array with an index. A typical array contains values of the same data type
(e.g. `float` numbers), as does a typical `Series`.

When it comes to geospatial raster
data, one dimension is not enough. Even the most basic raster, something like a
[digital terrain model](https://en.wikipedia.org/wiki/Digital_elevation_model) (DTM),
requires two dimensions. One represents longitude (or x when projected), while the other
latitude (or y), resulting in a 2-dimensional array.

But you don't have to stop there.
Take a typical satellite image. The longitude and latitude dimensions are still present,
but you have different bands representing blue, green, red and often near-infra-red
frequencies, resulting in a 3-dimensional array (`lon`, `lat`, `band`). Throw in time,
and you're now dealing with a 4-dimensional array (`lon`, `lat`, `band`, `time`).

All
these use cases fall under the umbrella of N-dimensional array handling covered by the
`xarray` package. Whereas a `pandas.Series` is a 1-dimensional array with an index,
`xarray.DataArray` is an N-dimensional array with N indexes. Combining multiple `Series`
gives you a `pandas.DataFrame`, where each column can have a different data type (e.g.
one numbers, other names). Combining multiple `xarray.DataArray`s gives you a
`xarray.Dataset`, where each array can have a different data type. There's a lot of
similarity between `pandas` and `xarray`, but also some differences.

Let's read some raster and explore `xarray` objects in practice.

```{python}
import datashader as ds
import geopandas as gpd
import rioxarray
import xarray as xr
import osmnx as ox
import matplotlib.pyplot as plt

from geocube.api.core import make_geocube
```

## Population grids

Today, you will be working with the data from the
[Global Human Settlement Layer](https://ghsl.jrc.ec.europa.eu/datasets.php) (GHSL)
developed by the Joint Research Centre of the European Commission. Unlike in all previous
hands-on sessions, the data is not pre-processed and you will read it directly from the
open data repository.

The first layer you will open is a population grid. GHSL covers the whole world divided into
a set of tiles, each covering an area of 1,000 by 1,000 km at a resolution of 100m per pixel.
The link below points to a single tile[^1] covering most of Eastern Europe.

[^1]: See the distribution of tiles in the [data repository](https://ghsl.jrc.ec.europa.eu/download.php?ds=pop).

```{python}
pop_url = (  # <1>
    "https://jeodpp.jrc.ec.europa.eu/ftp/jrc-opendata/GHSL/"
    "GHS_POP_GLOBE_R2023A/GHS_POP_E2030_GLOBE_R2023A_54009_100/"
    "V1-0/tiles/GHS_POP_E2030_GLOBE_R2023A_54009_100_V1_0_R4_C20.zip"
      )
pop_url
```
1. The URL is long. It may be better to write it as a multi-line string to avoid a long line.

The `pop_url` points to a ZIP file. Within that ZIP file is a
[GeoTIFF](https://en.wikipedia.org/wiki/GeoTIFF) containing the actual raster. There is
often no need to download and unzip the file as there's a good chance you can read it
directly.

### Reading rasters with `rioxarray`

`xarray`, like `pandas` is an agnostic library. It is designed for N-dimensional arrays
but not necessarily geospatial arrays (although that is often the case...). It means that
by default, it is not able to read geospatial file formats like GeoTIFF. That is where
`rioxarray` comes in. It comes with the support of the usual geo-specific things like
specific file formats or CRS.

```{python}
p = f"zip+{pop_url}!GHS_POP_E2030_GLOBE_R2023A_54009_100_V1_0_R4_C20.tif"  # <1>
population = rioxarray.open_rasterio(p, masked=True)    # <2>
population
```
1. Create a path to the file inside the ZIP. Add the `"zip+"` prefix and then the path to the actual file inside the archive, starting with `"!"`.
2. Use `rioxarray` to open the file using the lower-level `rasterio` package. With `masked=True` ensure, that the missing values are properly masked out.

Above, you can see the representation of the population grid as a `DataArray`. It has
three dimensions (`"band"`, `"x"`, `"y"`) with a resolution 1x10,000x10,000 and values as
`float`.

`rioxarray` gives you a handy `.rio` accessor on `xarray` objects, allowing you to access
geospatial-specific tools. Like retrieval of CRS.

```{python}
population.rio.crs
```

Or the extent of the raster (in the CRS shown above).

```{python}
population.rio.bounds()
```

The missing, masked data can be represented as as specific value, especially when dealing with
integer arrays. You can check which one:

```{python}
population.rio.nodata
```

### Plotting with `datashader`

Plotting a raster with a resolution of 10,000x10,000 pixels can be tricky. Often, the resolution
is even larger than that. The best way to plot is to resample the data to a smaller
resolution that better fits the screen. A handy tool that can do that quickly is
[`datashader`](https://datashader.org). Let's use it to plot the array as 600x600 pixels.

```{python}
canvas = ds.Canvas(plot_width=600, plot_height=600)     # <1>
agg = canvas.raster(population.where(population>0).sel(band=1)) # <2>
agg
```
1. Create a canvas with a specific resolution.
2. Select pixels with a population more than 0 (`population.where(population>0)`), select a single band to get 2-dimensional array (`.sel(band=1)`) and pass the result to the canvas.

You can see that the result is a new `xarray.DataArray` with a resolution 600x600. The
built-in matplotlib-based plotting can easily handle that.

```{python}
# | fig-cap: Population grid resampled to 600x600 pixels
_ = agg.plot()
```

## Clipping based on geometry

Daling with large rasters is often impractical if you are interested in a small subset,
for example, representing a single city.

### Functional Urban Areas

In this case, you may want to work only with the data covering Budapest, Hungary, defined by
its [functional urban area](https://ghsl.jrc.ec.europa.eu/ghs_fua.php) (FUA), available as
another data product on GHSL. FUAs are available as a single GeoPackage with vector
geometries.

```{python}
#| classes: explore
pop_url = (
    "https://jeodpp.jrc.ec.europa.eu/ftp/jrc-opendata/GHSL/" # <1>
    "GHS_FUA_UCDB2015_GLOBE_R2019A/V1-0/" # <1>
    "GHS_FUA_UCDB2015_GLOBE_R2019A_54009_1K_V1_0.zip" # <1>
) # <1>
p = f"zip+{pop_url}!GHS_FUA_UCDB2015_GLOBE_R2019A_54009_1K_V1_0.gpkg" # <2>
fuas = gpd.read_file(p) # <3>
budapest = fuas.query("eFUA_name == 'Budapest'") # <4>
budapest.explore()
```
1. Get the URL.
2. Specify the path to read the file from the ZIP.
3. Read the table with `geopandas`.
4. Filter only Budapest.

If you want to clip the `population` raster to the extent of Budapest FUA, you can use
the `clip` method from the `rioxarray` extension of `xarray`.

```{python}
population_bud = population.rio.clip(      # <1>
    budapest.to_crs(population.rio.crs).geometry # <2>
)
population_bud
```
1. Use `.rio.clip` to clip the geospatial raster to the extent of a geometry.
2. Ensure the `budapest` is in the same CRS as the `population` and pass its geometry.

The raster is no longer 10,000x10,000 pixels but only 840x830, covering the extent of Budapest
FUA. You can easily check that by plotting the clipped array.

```{python}
# | fig-cap: Population grid clipped to Budapest FUA
_ = population_bud.plot()
```

## Array manipulation

While this is technically a 3-dimensional array, the dimension `"band"` has only one value.
Normally, you would get a 2-dimensional array representing a selected band using the `.sel()`
method.

```{python}
population_bud.sel(band=1)
```

But if you have only one band, you can _squeeze_ the array and get rid of that dimension
that is not needed.

```{python}
population_bud = population_bud.squeeze()
population_bud
```

Now a lot what you know from `pandas` works equally in `xarray`. Getting the minimum:

```{python}
population_bud.min()
```

As expected, there are some cells with no inhabitants.

```{python}
population_bud.max()
```

The densest cell, on the other hand, has more than 600 people per hectare.

```{python}
population_bud.mean()
```

Mean is, however, only below 7.

```{python}
population_bud.median()
```

While the median is 0. There are a lot of cells with 0.

::: {.callout-tip}
# DataArray vs scalar

Notice that `xarray` always returns another `DataArray` even with a single value. If you
want to get that scalar value, you can use `.item()`.

```{python}
population_bud.mean().item()
```
:::

You can plot the distribution of values across the array.

```{python}
# | fig-cap: Histogram of population counts
_ = population_bud.plot.hist(bins=100)
```

Indeed, there are a lot of zeros. Let's filter them out and check the distribution again.

```{python}
# | fig-cap: Histogram of population counts excluding 0
_ = population_bud.where(population_bud>0).plot.hist(bins=100)
```

As with many observations in urban areas, this follows a power-law-like distribution
with a lot of observations with tiny values and only a few with large ones.

## Array operations

Let's assume that you want to normalise population counts by the built-up volume, which
is available as another GHSL product. This time, on a grid again.

```{python}
volume_url = (
    "https://jeodpp.jrc.ec.europa.eu/ftp/jrc-opendata/GHSL/"
    "GHS_BUILT_V_GLOBE_R2023A/GHS_BUILT_V_E2030_GLOBE_R2023A_54009_100/V1-0/tiles/"
    "GHS_BUILT_V_E2030_GLOBE_R2023A_54009_100_V1_0_R4_C20.zip"
)
volume_url
```

All work the same as before. You read the GeoTIFF as a `DataArray`.

```{python}
p = f"zip+{volume_url}!GHS_BUILT_V_E2030_GLOBE_R2023A_54009_100_V1_0_R4_C20.tif"
built_up = rioxarray.open_rasterio(p, masked=True)
built_up
```

And clip it to the same extent.

```{python}
built_up_bud = built_up.rio.clip(budapest.to_crs(built_up.rio.crs).geometry)
built_up_bud
```

You can quickly check how does it look like.

```{python}
# | fig-cap: Built-up volume
_ = built_up_bud.plot(cmap="magma_r")
```

The two grids are aligned, meaning that pixels with the same coordinates represent the
same area. This allows us to directly perform array algebra. Again, you know this from
`pandas`.

```{python}
pop_density = population_bud /  built_up_bud.squeeze()  # <1>
pop_density
```
1. Divide the population by built-up volume to get a normalised value.

The result is a new array that inherits spatial information (`spatial_ref`) but contains
newly computed values.

```{python}
# | fig-cap: Population grid normalised by the built-up volume
_ = pop_density.plot(cmap="cividis_r")
```

The resulting array can be then saved to a GeoTIFF using `rioxarray`.

```{python}
pop_density.rio.to_raster("population_density.tif")
```

## Zonal statistics with `geocube`

A typical operation when working with rasters is the transfer of values from an array
to a set of vector geometries. This is called _zonal statistics_ and can be done in many
ways, depending on the use case. When your polygons are large compared to cells of the array,
a good option is to use a `geocube` package.

### Downloading OpenStreetMap data

You may be interested in the average population density in individual districts of
Budapest. One option for getting the geometries representing the districts is the
[OpenStreetMap](https://www.openstreetmap.org/). Everything you can see on OpenStreetMap
is downloadable. In Python, a recommended way (when not doing large downloads) is the
`osmnx` package (imported as `ox`). The detailed explanation of `osmnx` is out of scope
for this session, but if you are interested in details, check the official
[Getting started](https://osmnx.readthedocs.io/en/stable/getting-started.html) guide.

```{python}
admin_level_9 = ox.features_from_place("Budapest", {"admin_level": "9"})    # <1>
districts = admin_level_9[admin_level_9.geom_type == "Polygon"][    # <2>
    ["name", "name:en", "geometry"]     # <3>
]
districts["key"] = range(len(districts))    # <4>
```
1. Use `features_from_place` to download features from Budapest. But filter only those tagged with the `admin_level` equal to 9.
2. Filter only polygons. The `GeoDataFrame` coming from `osmnx` also contains many LineStrings.
3. Retain only three columns that may be useful.
4. Create a new column with a _key_ - an integer value unique to each observation. That will be useful later.

### Plotting raster and vector together

Both `xarray` and `geopandas` can create `matplotlib` plots that can be combined to see how the two overlap.

```{python}
# | fig-cap: Overlay of district boundaries over population density
f, ax = plt.subplots()     # <1>
pop_density.plot(ax=ax, cmap="cividis_r")     # <2>
districts.to_crs(pop_density.rio.crs).plot( # <3>
    ax=ax, facecolor="none", edgecolor="red", linewidth=1, aspect=None # <4>
);
```
1. Create an empty figure and an axis.
2. Plot the population density to the axis.
3. Plot the `districts` to the same array, ensuring it is in the same projection.
4. Specify the plotting style and disable the automatic setting of the aspect to keep the axis as returned by `xarray`.

### Zonal statistics

Zonal statistics using `geocube` has three conceptual phases.

1. Convert the geometry to an aligned raster, bringing the ID of each polygon to a raster format.
2. Merge of the two arrays.
3. Groupby operation using the IDs as grouping keys.

Let's start with the first one.

```{python}
districts_grid = make_geocube(      # <1>
    vector_data=districts,  # <2>
    measurements=["key"],   # <3>
    like=pop_density, # <4>
)
districts_grid
```
1. Use `make_geocube` imported from `geocube`.
2. You want to rasterise `districts` `GeoDataFrame`.
3. Use the values in the `"key"` column as values of the resulting array.
4. Make the array look like `pop_density` to ensure the two are exactly aligned.

You can visually check the resulting raster by plotting the `"key"` variable.

```{python}
# | fig-cap: Rasterised districts
_ = districts_grid.key.plot.imshow(cmap="tab20")  # <1>
```
1. `"tab20"` is a categorical colour map suitable for the categorical variable stored in `"key"`.

The second and third steps outlined above can be combined into a single one.
You can directly group `pop_density` by the array stored in `districts_grid.key`.

```{python}
grouped_density = pop_density.groupby(districts_grid.key)
grouped_density
```

This gives you a similar `GroupBy` object you know from `pandas`. You can get any type
of aggregation from the object and assign it directly back to the `GeoDataFrame`.

```{python}
districts["mean_density"] = grouped_density.mean()
```

Check the result!

```{python}
#| classes: explore
districts.explore("mean_density", cmap="cividis_r", tiles="CartoDB Positron")
```

::: {.callout-tip}
# Additional reading

Have a look at the chapter
[_Local Spatial Autocorrelation_](https://geographicdata.science/book/notebooks/07_local_autocorrelation.html#bonus-local-statistics-on-surfaces)
from the Geographic Data Science with Python by @rey2023geographic to learn how to do LISA on rasters.
:::